{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **energyexplorer.io: data pipeline overview**\n",
    "\n",
    "### **General overview of key steps:**\n",
    "\n",
    "1: Get API key from NSRDB site and put in .gitignore \\\n",
    "2: Download radiation data from website and store as site_generation \\\n",
    "3: Run df through pySAM and export generation data to df - you should \\\n",
    "4: Download LMP data using script from CAISO_API.ipynb wrapper that Ranjit made \\\n",
    "5: Combine dataframes and calculate LCOE \\\n",
    "\n",
    "Use this tutorial for importing data: https://developer.nrel.gov/docs/solar/nsrdb/python-examples/\n",
    "\n",
    "### **Directions for navigating notebook**\n",
    "\n",
    "1: Follow the steps in each section to walk through the analysis performed to calculate the levelized cost of energy (LCOE) and net present value (NPV) of future cash flows for the user requested plant. \\\n",
    "2: Ignore sections of code with \"SITE DEVELOPER ONLY\" commented above them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 1. Get API Key from the National Renewable Energy Lab's (NREL) National Solar Radiation Database (NSRDB)**\n",
    "\n",
    "#### **Section purpose**\n",
    "\n",
    "This notebook remotely accesses solar radiation datasets using NSRDB's API. These datasets are used to calculate the annual solar radiation potential at a user defined latitude and longitude. \n",
    "\n",
    "To recieve data from the NSRDB's API, an API Key must be passed along with your data request.\n",
    "\n",
    "#### **Directions for API**\n",
    "\n",
    "1: Follow this link to sign up for an api key: https://developer.nrel.gov/signup/ (note: Data hosting and access is a free service provide by NREL, no finanical information is required to get your key.) \\\n",
    "2: When you have acquired your API Key replace text: \"ENTER YOUR NSRDB API KEY HERE\" with the API Key. Keep the quotes surrounding your API Key. \\\n",
    "3: Run code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# API Key to access National Solar Radiation Database (NSRDB) #\n",
    "###############################################################\n",
    "\n",
    "class creds:\n",
    "    api_key = \"ENTER YOUR NSRDB API KEY HERE\"\n",
    "\n",
    "##############################################################\n",
    "# SITE DEVELOPER ONLY -- store API Key in creds.py ###########\n",
    "# Import API Key via creds.py ################################\n",
    "##############################################################\n",
    "\n",
    "#import creds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 2. Import packages**\n",
    "\n",
    "#### **Section purpose**\n",
    "\n",
    "In this section, you import packages used by the data pipeline for data import an analysis. This interactive jupyter notebook is being hosted by a [JupyterLite](https://jupyterlite.readthedocs.io/en/latest/) server, a separate server from energyexplorer.io.\n",
    "\n",
    "Because of this, we will need to install some packages that do not come natively with JupyterLite's kernel [Pyodide](https://pyodide.org/en/stable/). For a full list of packages included with JupyterLite, [click here](https://github.com/jupyterlite/jupyterlite/tree/main/packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Pyodide non-included packages install #############################################\n",
    "# SITE DEVELOPER ONLY -- comment out these installs as packages are already in venv #\n",
    "#####################################################################################\n",
    "\n",
    "%pip install NREL-PySAM\n",
    "%pip install pycaiso\n",
    "%pip install requests\n",
    "\n",
    "########################################\n",
    "# Pyodide non-included packages import #\n",
    "########################################\n",
    "\n",
    "# Import PySAM. This package provides python functions used to convert raw solar radiation values into energy generation based on the engineering parameters provided by the user\n",
    "# Learn more about PySAM here: https://pypi.org/project/NREL-PySAM/\n",
    "\n",
    "# Use site.addsitedir() to set the path to the SAM SDK API. Set path to the python directory.\n",
    "import site\n",
    "site.addsitedir('/Applications/sam-sdk-2015-6-30-r3/languages/python/')\n",
    "import PySAM.PySSC as pssc\n",
    "\n",
    "# Import pycasio. This package provides functions used to remotely access the California Independent System Operator's (CAISO) historical wholesale market price data.\n",
    "# CAISO oversees the operation of California's bulk electric power system, transmission lines, and electricity market generated and transmitted by its member utilities.\n",
    "# Learn more about CAISO here: https://www.caiso.com/Pages/default.aspx\n",
    "\n",
    "import requests\n",
    "from pycaiso.oasis import Node\n",
    "\n",
    "########################################\n",
    "# Pyodide included packages import #####\n",
    "########################################\n",
    "\n",
    "# General data wrangling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "# File management\n",
    "\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. User parameter inputs are passed from home page model form to dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = {\n",
    "    'project_latitude': 35.21803686349634,\n",
    "    'project_longitude': -116.94075390362501,\n",
    "    'project_lifetime': 25,\n",
    "    'project_type': 'solar',\n",
    "    'installed_capacity': 100,\n",
    "    'battery_capacity': 400,\n",
    "    'max_charge_rate': 100,\n",
    "    'max_discharge_rate': 100,\n",
    "    'dc_ac_ratio': 1.1,\n",
    "    'tilt': 25,\n",
    "    'azimuth': 180,\n",
    "    'inv_eff': 96,\n",
    "    'losses': 14.0757,\n",
    "    'array_type': 0,\n",
    "    'gcr': 0.4,\n",
    "    'adjust:constant': 0,\n",
    "    'capital_cost_per_mwh': 890000, # example value used from https://www.nrel.gov/docs/fy22osti/80694.pdf - page 19\n",
    "    'fixed_per_mwh': 16060, # example value used from https://www.nrel.gov/docs/fy22osti/80694.pdf\n",
    "    'real_discount_rate': .05,\n",
    "    'tax_credit': .30,\n",
    "    'subsidy': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pull historical solar radiation at requested lat, lon point from database\n",
    "\n",
    "#### a. Prepare url for data import\n",
    "\n",
    "Future development:\n",
    "- need to decide what year of data should be pulled (or if multiple years should be pulled and averaged?)\n",
    "- pull data once instead of twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare all variables as strings. Spaces must be replaced with '+', i.e., change 'John Smith' to 'John+Smith'.\n",
    "\n",
    "# Define the lat, long of the location and the year\n",
    "lat, lon, year = user_inputs['project_latitude'], user_inputs['project_longitude'], 2010\n",
    "\n",
    "# lat = input() #testing input function\n",
    "# Pull api key object from creds.py\n",
    "api = creds.api_key\n",
    "\n",
    "# Set the attributes to extract (e.g., dhi, ghi, etc.), separated by commas.\n",
    "attributes = 'ghi,dhi,dni,wind_speed,air_temperature,solar_zenith_angle'\n",
    "\n",
    "# Choose year of data\n",
    "year = '2020'\n",
    "\n",
    "# Set leap year to true or false. True will return leap day data if present, false will not.\n",
    "leap_year = 'false'\n",
    "\n",
    "# Set time interval in minutes, i.e., '30' is half hour intervals. Valid intervals are 30 & 60.\n",
    "interval = '60'\n",
    "\n",
    "# Specify Coordinated Universal Time (UTC), 'true' will use UTC, 'false' will use the local time zone of the data.\n",
    "# NOTE: In order to use the NSRDB data in SAM, you must specify UTC as 'false'. SAM requires the data to be in the\n",
    "# local time zone.\n",
    "utc = 'false'\n",
    "\n",
    "# Your full name, use '+' instead of spaces.\n",
    "your_name = 'Tom+Wheeler'\n",
    "\n",
    "# Your reason for using the NSRDB.\n",
    "reason_for_use = 'research'\n",
    "\n",
    "# Your affiliation\n",
    "your_affiliation = 'UCSB'\n",
    "\n",
    "# Your email address\n",
    "your_email = 'tbwheeler@ucsb.edu'\n",
    "\n",
    "# Please join our mailing list so we can keep you up-to-date on new developments.\n",
    "mailing_list = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Pull dataset from api and save to pandas dataframe named df\n",
    "\n",
    "Future development:\n",
    "-need to conditionally check that dataframe always has 8760 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timezone and elevation objects for use in SAM model\n",
    "# Declare url string\n",
    "url = 'https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap}&interval={interval}&utc={utc}&full_name={name}&email={email}&affiliation={affiliation}&mailing_list={mailing_list}&reason={reason}&api_key={api}&attributes={attr}'.format(year=year, lat=lat, lon=lon, leap=leap_year, interval=interval, utc=utc, name=your_name, email=your_email, mailing_list=mailing_list, affiliation=your_affiliation, reason=reason_for_use, api=api, attr=attributes)\n",
    "\n",
    "# Return just the first 2 lines to get metadata:\n",
    "info = pd.read_csv(url, nrows=1)\n",
    "\n",
    "# Assign timezone and elevation objects\n",
    "timezone, elevation = info['Local Time Zone'], info['Elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all but first 2 lines of csv to get data:\n",
    "site_generation = pd.read_csv('https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap}&interval={interval}&utc={utc}&full_name={name}&email={email}&affiliation={affiliation}&mailing_list={mailing_list}&reason={reason}&api_key={api}&attributes={attr}'.format(year=year, lat=lat, lon=lon, leap=leap_year, interval=interval, utc=utc, name=your_name, email=your_email, mailing_list=mailing_list, affiliation=your_affiliation, reason=reason_for_use, api=api, attr=attributes), skiprows=2)\n",
    "\n",
    "# Set the time index in the pandas dataframe:\n",
    "site_generation = site_generation.set_index(pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "\n",
    "# take a look\n",
    "# print('shape:', site_generation.shape)\n",
    "site_generation.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Import SAM simulation module to convert solar radiation data into energy output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = pssc.PySSC()\n",
    "\n",
    "# Resource inputs for SAM model:\n",
    "# Must be byte strings\n",
    "wfd = ssc.data_create()\n",
    "ssc.data_set_number(wfd, b'lat', user_inputs['project_latitude'])\n",
    "ssc.data_set_number(wfd, b'lon', user_inputs['project_longitude'])\n",
    "ssc.data_set_number(wfd, b'tz', timezone)\n",
    "ssc.data_set_number(wfd, b'elev', elevation)\n",
    "ssc.data_set_array(wfd, b'year', site_generation.index.year)\n",
    "ssc.data_set_array(wfd, b'month', site_generation.index.month)\n",
    "ssc.data_set_array(wfd, b'day', site_generation.index.day)\n",
    "ssc.data_set_array(wfd, b'hour', site_generation.index.hour)\n",
    "ssc.data_set_array(wfd, b'minute', site_generation.index.minute)\n",
    "ssc.data_set_array(wfd, b'dn', site_generation['DNI'])\n",
    "ssc.data_set_array(wfd, b'df', site_generation['DHI'])\n",
    "ssc.data_set_array(wfd, b'wspd', site_generation['Wind Speed'])\n",
    "ssc.data_set_array(wfd, b'tdry', site_generation['Temperature'])\n",
    "\n",
    "# Create SAM compliant object  \n",
    "dat = ssc.data_create()\n",
    "ssc.data_set_table(dat, b'solar_resource_data', wfd)\n",
    "ssc.data_free(wfd)\n",
    "\n",
    "# Specify the system Configuration\n",
    "# Set system capacity in MW\n",
    "# system_capacity = 4\n",
    "\n",
    "ssc.data_set_number(dat, b'system_capacity', user_inputs['installed_capacity'])\n",
    "# Set DC/AC ratio (or power ratio). See https://sam.nrel.gov/sites/default/files/content/virtual_conf_july_2013/07-sam-virtual-conference-2013-woodcock.psite_generation\n",
    "ssc.data_set_number(dat, b'dc_ac_ratio', user_inputs['dc_ac_ratio'])\n",
    "# Set tilt of system in degrees\n",
    "ssc.data_set_number(dat, b'tilt', user_inputs['tilt'])\n",
    "# Set azimuth angle (in degrees) from north (0 degrees)\n",
    "ssc.data_set_number(dat, b'azimuth', user_inputs['azimuth'])\n",
    "# Set the inverter efficency\n",
    "ssc.data_set_number(dat, b'inv_eff', user_inputs['inv_eff'])\n",
    "# Set the system losses, in percent\n",
    "ssc.data_set_number(dat, b'losses', user_inputs['losses'])\n",
    "# Specify fixed tilt system (0=Fixed, 1=Fixed Roof, 2=1 Axis Tracker, 3=Backtracted, 4=2 Axis Tracker)\n",
    "ssc.data_set_number(dat, b'array_type', user_inputs['array_type'])\n",
    "# Set ground coverage ratio\n",
    "ssc.data_set_number(dat, b'gcr', user_inputs['gcr'])\n",
    "# Set constant loss adjustment\n",
    "ssc.data_set_number(dat, b'adjust:constant', user_inputs['adjust:constant'])\n",
    "\n",
    "# execute and put generation results back into dataframe\n",
    "mod = ssc.module_create(b'pvwattsv5')\n",
    "ssc.module_exec(mod, dat)\n",
    "site_generation['Generation (MW)'] = np.array(ssc.data_get_array(dat, b'gen'))\n",
    "\n",
    "# free the memory\n",
    "ssc.data_free(dat)\n",
    "ssc.module_free(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide sum of generation by the number of periods times the system size\n",
    "site_generation['Generation (MW)'].sum() / (525600/int(interval) * user_inputs['installed_capacity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_generation['Generation (MW)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find nearest node to user lat lon\n",
    "\n",
    "- Full CAISO node dataset is from this repo: https://github.com/emunsing/CAISO-Scrapers\n",
    "- Dataset xlsx is hosted here: https://github.com/emunsing/CAISO-Scrapers/blob/master/LMP%20Location%20Scraper/LMPLocations_vs_FullList.xls\n",
    "\n",
    "Future development:\n",
    "-Should Generation Nodes be filtered out? (i.e. show only load nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_locations = pd.read_csv('data/LMPLocations.csv')\n",
    "\n",
    "nodes_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_locations = pd.read_csv('data/LMPLocations.csv')\n",
    "\n",
    "# find absolute value of user input lat/lon and node dataset lat/lon\n",
    "# and subtract data lat/lon from user input lat/lons to get differences from user supplied lat lons\n",
    "nodes_locations['latitude difference'] = abs(user_inputs['project_latitude']) - nodes_locations['latitude'].abs()\n",
    "nodes_locations['longitude difference'] = abs(user_inputs['project_longitude']) - nodes_locations['longitude'].abs()\n",
    "\n",
    "# add up absolute value of differences to find total difference then df by total difference to find location with the smallest total difference (the nearest node)\n",
    "nodes_locations['total difference'] = nodes_locations['latitude difference'].abs() + nodes_locations['longitude difference'].abs() \n",
    "nodes_locations =nodes_locations.sort_values(by=['total difference'])\n",
    "\n",
    "#extra desired node\n",
    "node_request = nodes_locations['name'].iat[0]\n",
    "node_request_lat = nodes_locations['latitude'].iat[0]\n",
    "node_request_lon = nodes_locations['longitude'].iat[0]\n",
    "print(node_request)\n",
    "\n",
    "#show full dataframe\n",
    "nodes_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Connect to CAISO API and pull down historical LMP data for nearest node\n",
    "\n",
    "Note: Due to CAISO API timing out after only pulling 1 month of records (need to pull 12), the app temporarily pulls in a static dataset that was manually collected to complete the hw assignment back in Ranjit's class in February 2022. When API is working again, uncomment below code chunk, lmp dataset will be named the same for both the static dataset and the dataset pulled in via api.\n",
    "\n",
    "See directory 'api reference/caiso-api.ipynb' for code that was used to build below code chunk (provided by Ranjit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pull in historical node data from CAISO api\n",
    "# # IMPORTANT: CAN ONLY BE PULLED IN 1 MONTH AT A TIME SO MUST RUN FOR LOOP\n",
    "\n",
    "# # assign nearest node to desired node for import and use 2020 as import year. Caiso API does not support any earlier years (possibly in archives).\n",
    "# node = Node(node_request)\n",
    "# yr = 2020\n",
    "\n",
    "# # initalize dataframe to append data imports from CAISO API\n",
    "# node_lmps = pd.DataFrame()\n",
    "\n",
    "# #change 3 to 12 to get full year\n",
    "# for m in range(1,3):\n",
    "#     print(m)\n",
    "#     num_days = monthrange(yr, m)[1]\n",
    "#     print(num_days)\n",
    "#     node_lmps_month = node.get_month_lmps(yr, m)\n",
    "# #     node_lmps_month = node.get_lmps(datetime(yr, m, num_days))\n",
    "#     node_lmps = node_lmps.append(node_lmps_month, ignore_index=True)\n",
    "#     time.sleep(5)\n",
    "# #     node_lmps_month_last_day = node.get_lmps(datetime(yr, m, num_days))\n",
    "# #     node_lmps = node_lmps.append(node_lmps_month_last_day, ignore_index=True)\n",
    "# #     time.sleep(5)\n",
    "#     print(node_lmps.head())\n",
    "\n",
    "# #filter node_lmps output by only LMP\n",
    "# lmp_only = node_lmps.query(\"LMP_TYPE == 'LMP'\")\n",
    "\n",
    "# lmp_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily pull static dataset (2020 from HOLLISTR_1_N101 node)\n",
    "\n",
    "lmp_only = pd.read_csv('data/LMP_Historic_price.csv')\n",
    "\n",
    "# formatting dataframe to prepare for joining with power generation data\n",
    "\n",
    "# replace T and miliseconds with blank and convert to datetime\n",
    "lmp_only['INTERVALENDTIME_GMT'] = lmp_only['INTERVALENDTIME_GMT'].str.replace('T',' ')\n",
    "lmp_only['INTERVALENDTIME_GMT'] = lmp_only['INTERVALENDTIME_GMT'].str.replace('-00:00','')\n",
    "lmp_only['INTERVALENDTIME_GMT'] = pd.to_datetime(lmp_only['INTERVALENDTIME_GMT'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "lmp_only = lmp_only[['INTERVALENDTIME_GMT','OPR_HR', 'NODE', 'LMP_TYPE', 'MW']].sort_values(by='INTERVALENDTIME_GMT')\n",
    "\n",
    "lmp_only.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Join site_generation (energy generation output at site) and lmp_only (historical marginal price at nearest wholesale node) to prepare for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join generation and lmp dataframes on time\n",
    "\n",
    "# drop datetime index and make into column named index\n",
    "site_generation.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename time column to be be index so join can be performed using index column\n",
    "lmp_only = lmp_only.rename(columns={'INTERVALENDTIME_GMT': 'index'})\n",
    "\n",
    "# merge lmp_only and site_generation on index\n",
    "# note: rows where date and time do not match will be dropped using inner join leading to a dataframe that is less than 8760 lines\n",
    "lmp_generation_combined = pd.merge(site_generation, lmp_only, how='inner', on='index')\n",
    "\n",
    "# print out the number of rows dropped to see how much mismatch there was between dfs\n",
    "number_of_dropped_rows = 8760 - lmp_generation_combined.shape[0]\n",
    "# print(f'{number_of_dropped_rows} rows were droped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. (Part 2) If project has a battery associated with it, build script to determine how their earnings would change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmp_generation_combined = lmp_generation_combined[['index', 'Generation (MW)', 'NODE', 'MW']]\n",
    "lmp_generation_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem statement ###\n",
    "# 1. Must check that \n",
    "\n",
    "##########################################################\n",
    "#### Create lists to store and test dataframe outputs ####\n",
    "##########################################################\n",
    "\n",
    "# with_battery_total = []\n",
    "\n",
    "# without_battery_total = []\n",
    "\n",
    "# difference_battery = []\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "##########################################################\n",
    "###### Add date and hour values to columns in df #########\n",
    "##########################################################\n",
    "\n",
    "# create a new column using index column which has only the day, month, and year on each row\n",
    "lmp_generation_combined['index_day_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.date\n",
    "\n",
    "# create a new column using index column which has only the time\n",
    "lmp_generation_combined['index_hour_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.hour\n",
    "\n",
    "# split main dataframe into 365 subdataframes each with the same index_day_only value\n",
    "daily_energy_dfs = {}\n",
    "for idx, v in enumerate(lmp_generation_combined['index_day_only'].unique()):\n",
    "    daily_energy_dfs[f'df{idx}'] = lmp_generation_combined.loc[lmp_generation_combined['index_day_only'] == v]\n",
    "\n",
    "# loop through the list of 365 dataframes, 1 dataframe at a time\n",
    "for day in np.arange(0, len(daily_energy_dfs), 1):\n",
    "    \n",
    "    # loop through the list of 365 dataframes, 1 dataframe at a time. assign current dataframe to current_df\n",
    "    current_df = daily_energy_dfs[f'df{day}'].loc[:]\n",
    "\n",
    "    # isolate df with only hours in the day where (1) there is no solar generation (2) the hour of the day is past 12 | and sort df with highest priced hours on top\n",
    "    top_values_current_day = current_df[current_df['Generation (MW)'] == 0].sort_values('MW', ascending = False).query(\"index_hour_only > 12\")\n",
    "\n",
    "    # Sort by lowest day ahead price on top to highest price on bottom. We'll assume historical data is exactly representative of day ahead hourly prices.\n",
    "    # Filter out non-producing hours as we assume battery system can only be filled by the solar system. \n",
    "    # These are the hours we'll want to be filling the battery.\n",
    "    bot_values_current_day = current_df[current_df['Generation (MW)'] != 0].sort_values('MW')\n",
    "\n",
    "    # Assign current battery charge to 0 at beginning of the day\n",
    "    # Assume battery is discharged down to 1 at night (cannot be 0 or battery_discharge_hour_counter will not function properly)\n",
    "    current_battery_charge = .00001\n",
    "\n",
    "    # Calculate earnings per hour if plant had no battery\n",
    "    current_df['earnings_per_hour'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Iterate through each row in bot_values_current_day dataframe\n",
    "    for hour in reversed(np.arange(0, len(bot_values_current_day), 1)):\n",
    "\n",
    "        # Check if battery is below capacity\n",
    "        # If battery is fully charged for the day, this loop will end\n",
    "        if current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "            # calculate what hour in the evening the battery will discharge\n",
    "            # for example: if the battery has been charged up to 70 MWh out of 400 MWh of capacity and the max discharge rate is 100 MW per hour then the current 70 MWh would be discharged in the first hour\n",
    "            # for example: if the battery has been charged up to 130 MWh out of 400 MWh of capacity and the max discharge rate is 100 MW per hour then the first 100 MWs would be discharged in the first hour and the remaining 30 MWs in the second\n",
    "            battery_discharge_hour_counter = int(np.ceil(current_battery_charge / user_inputs['max_discharge_rate'])) - 1\n",
    "\n",
    "            # Conditionally check if the price per MW during the hour that this generation would be discharged to the grid is higher than the price that is currently being asking for\n",
    "            if top_values_current_day['MW'].iat[battery_discharge_hour_counter] > bot_values_current_day['MW'].iat[hour]:\n",
    "\n",
    "                # If battery is below capacity, conditionally decide how much to fill the battery\n",
    "\n",
    "                # If total generation in that hour is more than max charging rate, then charge battery to max charge rate\n",
    "                if bot_values_current_day['Generation (MW)'].iat[hour] > user_inputs['max_charge_rate']:\n",
    "\n",
    "                    add_charge = user_inputs['max_charge_rate']\n",
    "\n",
    "                # Else charge the battery with that hour's solar system generation (which should be less than or equal to user_inputs['max_charge_rate'])\n",
    "                else:\n",
    "\n",
    "                    add_charge = bot_values_current_day['Generation (MW)'].iat[hour]\n",
    "\n",
    "                # Subtract the amount of charge added from the Generation for that hour\n",
    "                bot_values_current_day['Generation (MW)'].iat[hour] = bot_values_current_day['Generation (MW)'].iat[hour] - add_charge\n",
    "\n",
    "                # Update current battery charge with charge added\n",
    "                current_battery_charge = current_battery_charge + add_charge\n",
    "\n",
    "                # Check to see if battery capacity was exceeded (overflow charge) by adding new charge to current battery charge\n",
    "                if current_battery_charge > user_inputs['battery_capacity']:\n",
    "\n",
    "                    # Calculate overflow charge (the amount of excess charge 'sent' to the battery)\n",
    "                    extra_charge = current_battery_charge - user_inputs['battery_capacity']\n",
    "\n",
    "                    # Set current battery charge to battery_capacity by subtracting the extra charge from the total current_battery_charge\n",
    "                    current_battery_charge = current_battery_charge - extra_charge\n",
    "\n",
    "                    # Assign the overflow charge to be the generation sent to the grid for that hour. This will be the first hour on the bot_values_current_day dataframe that energy will be immediately sold to the grid\n",
    "                    bot_values_current_day['Generation (MW)'].iat[hour] = extra_charge\n",
    "\n",
    "        else:\n",
    "\n",
    "            break\n",
    "    \n",
    "\n",
    "    #Overwrite current_df generation values with bot_values_current_day to reflect energy sent to battery instead of grid\n",
    "    current_df = current_df.set_index('index')\n",
    "    current_df.update(bot_values_current_day.set_index('index'))\n",
    "    current_df = current_df.reset_index()\n",
    "\n",
    "    ###############################################\n",
    "    ### Calculate solar revenue for current day ###\n",
    "    ###############################################\n",
    "\n",
    "    # Calculate the earning per hour for solar only\n",
    "    current_df['earnings_per_hour_solar'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Assign total revenue for that day from solar as an object\n",
    "    #solar_revenue_sum = bot_values_current_day['earnings_per_hour_solar'].sum()\n",
    "\n",
    "    #################################################\n",
    "    ### Calculate battery revenue for current day ###\n",
    "    #################################################\n",
    "\n",
    "    #update battery discharge counter again to account for last charge added to battery\n",
    "    battery_discharge_hour_counter = int(np.ceil(current_battery_charge / user_inputs['max_discharge_rate']))\n",
    "\n",
    "    add_charge_current_day = current_df[current_df['Generation (MW)'] == 0].sort_values('MW', ascending=False).query(\"index_hour_only > 12\").nlargest(n= battery_discharge_hour_counter, columns = 'MW')\n",
    "    \n",
    "    if current_battery_charge > user_inputs['max_discharge_rate'] and current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "        add_charge_current_day['battery_discharge'].iat[-1] = current_battery_charge % user_inputs['max_discharge_rate']\n",
    "\n",
    "    elif current_battery_charge == user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "    else:\n",
    "        \n",
    "        add_charge_current_day['battery_discharge'] = current_battery_charge\n",
    "    \n",
    "    add_charge_current_day['earnings_from_battery'] = add_charge_current_day['battery_discharge'] * add_charge_current_day['MW']\n",
    "\n",
    "    # create final df with solar earnings and battery earnings by hour\n",
    "    current_df = current_df.merge(add_charge_current_day[['index','battery_discharge','earnings_from_battery']], on='index', how='left')\n",
    "\n",
    "    #compare totals\n",
    "    # with_battery = current_df['earnings_from_battery'].sum() + current_df['earnings_per_hour_solar'].sum()\n",
    "    # without_battery = current_df['earnings_per_hour'].sum()\n",
    "\n",
    "    # #\n",
    "    # with_battery_total.append(with_battery)\n",
    "    # without_battery_total.append(without_battery)\n",
    "    # difference_battery.append(with_battery - without_battery)\n",
    "    all_dfs.append(current_df)\n",
    "\n",
    "generation_with_battery = pd.concat(all_dfs).fillna(0)\n",
    "\n",
    "generation_with_battery['earnings_from_battery_and_solar'] = generation_with_battery['earnings_per_hour_solar'] + generation_with_battery['earnings_from_battery']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_with_battery['earnings_from_battery_and_solar'].sum() - generation_with_battery['earnings_per_hour'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt at battery script\n",
    "- goal in this script is to check each row where energy is being generated against all future rows (including rows where energy is being generated and immediately sold to the grid) with the goal of discharging the battery during hours when the solar plant is producing energy and when it's not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem statement ###\n",
    "# 1. Must check that \n",
    "\n",
    "##########################################################\n",
    "#### Create lists to store and test dataframe outputs ####\n",
    "##########################################################\n",
    "\n",
    "with_battery_total = []\n",
    "\n",
    "without_battery_total = []\n",
    "\n",
    "difference_battery = []\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "##########################################################\n",
    "###### Add date and hour values to columns in df #########\n",
    "##########################################################\n",
    "\n",
    "# create a new column using index column which has only the day, month, and year on each row\n",
    "lmp_generation_combined['index_day_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.date\n",
    "\n",
    "# create a new column using index column which has only the time\n",
    "lmp_generation_combined['index_hour_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.hour\n",
    "\n",
    "# split main dataframe into 365 subdataframes each with the same index_day_only value\n",
    "daily_energy_dfs = {}\n",
    "for idx, v in enumerate(lmp_generation_combined['index_day_only'].unique()):\n",
    "    daily_energy_dfs[f'df{idx}'] = lmp_generation_combined.loc[lmp_generation_combined['index_day_only'] == v]\n",
    "\n",
    "# loop through the list of 365 dataframes, 1 dataframe at a time\n",
    "for day in np.arange(0, len(daily_energy_dfs), 1):\n",
    "    \n",
    "    # loop through the list of 365 dataframes, 1 dataframe at a time. assign current dataframe to current_df\n",
    "    current_df = daily_energy_dfs[f'df{day}'].loc[:]\n",
    "\n",
    "    # Assign current battery charge to 0 at beginning of the day\n",
    "    # Assume battery is discharged down to 1 at night (cannot be 0 or battery_discharge_hour_counter will not function properly)\n",
    "    current_battery_charge = 1\n",
    "\n",
    "    # Calculate earnings per hour if plant had no battery to use for comparison\n",
    "    current_df['earnings_per_hour'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Iterate through each row in current_df dataframe\n",
    "    for hour in np.arange(0, len(current_df), 1):\n",
    "\n",
    "        # Check if battery is below capacity\n",
    "        # If battery is fully charged for the day, this loop will end\n",
    "        if current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "            for sub_hour in np.arange(0, len(current_df), 1):\n",
    "\n",
    "                # if price in current hour in first loop is less than the price in current hour in second loop AND the current hour in the first loop is less than the second loop (i.e. the hour in the day is further ahead)\n",
    "                if current_df['MW'].iat[hour] < current_df['MW'].iat[sub_hour] and current_df['index_hour_only'].iat[hour] < current_df['index_hour_only'].iat[sub_hour]:\n",
    "\n",
    "                    # If total generation in that hour is more than max charging rate, then charge battery to max charge rate\n",
    "                    if bot_values_current_day['Generation (MW)'].iat[hour] > user_inputs['max_charge_rate']:\n",
    "                    \n",
    "                        add_charge = user_inputs['max_charge_rate']\n",
    "    \n",
    "                    # Else charge the battery with that hour's solar system generation (which should be less than or equal to user_inputs['max_charge_rate'])\n",
    "                    else:\n",
    "                    \n",
    "                        add_charge = bot_values_current_day['Generation (MW)'].iat[hour]\n",
    "\n",
    "                # Subtract the amount of charge added from the Generation for that hour\n",
    "                bot_values_current_day['Generation (MW)'].iat[hour] = bot_values_current_day['Generation (MW)'].iat[hour] - add_charge\n",
    "\n",
    "                # Update current battery charge with charge added\n",
    "                current_battery_charge = current_battery_charge + add_charge\n",
    "\n",
    "                # Check to see if battery capacity was exceeded (overflow charge) by adding new charge to current battery charge\n",
    "                if current_battery_charge > user_inputs['battery_capacity']:\n",
    "\n",
    "                    # Calculate overflow charge (the amount of excess charge 'sent' to the battery)\n",
    "                    extra_charge = current_battery_charge - user_inputs['battery_capacity']\n",
    "\n",
    "                    # Set current battery charge to battery_capacity by subtracting the extra charge from the total current_battery_charge\n",
    "                    current_battery_charge = current_battery_charge - extra_charge\n",
    "\n",
    "                    # Assign the overflow charge to be the generation sent to the grid for that hour. This will be the first hour on the bot_values_current_day dataframe that energy will be immediately sold to the grid\n",
    "                    bot_values_current_day['Generation (MW)'].iat[hour] = extra_charge\n",
    "\n",
    "        else:\n",
    "\n",
    "            break\n",
    "    \n",
    "\n",
    "    #Overwrite current_df generation values with bot_values_current_day to reflect energy sent to battery instead of grid\n",
    "    current_df = current_df.set_index('index')\n",
    "    current_df.update(bot_values_current_day.set_index('index'))\n",
    "    current_df = current_df.reset_index()\n",
    "\n",
    "    ###############################################\n",
    "    ### Calculate solar revenue for current day ###\n",
    "    ###############################################\n",
    "\n",
    "    # Calculate the earning per hour for solar only\n",
    "    current_df['earnings_per_hour_solar'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Assign total revenue for that day from solar as an object\n",
    "    #solar_revenue_sum = bot_values_current_day['earnings_per_hour_solar'].sum()\n",
    "\n",
    "    #################################################\n",
    "    ### Calculate battery revenue for current day ###\n",
    "    #################################################\n",
    "\n",
    "    #update battery discharge counter again to account for last charge added to battery\n",
    "    battery_discharge_hour_counter = int(np.ceil(current_battery_charge / user_inputs['max_discharge_rate']))\n",
    "\n",
    "    add_charge_current_day = current_df[current_df['Generation (MW)'] == 0].sort_values('MW', ascending=False).query(\"index_hour_only > 12\").nlargest(n= battery_discharge_hour_counter, columns = 'MW')\n",
    "    \n",
    "    if current_battery_charge > user_inputs['max_discharge_rate'] and current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "        add_charge_current_day['battery_discharge'].iat[-1] = current_battery_charge % user_inputs['max_discharge_rate']\n",
    "\n",
    "    elif current_battery_charge == user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "    else:\n",
    "        \n",
    "        add_charge_current_day['battery_discharge'] = current_battery_charge\n",
    "    \n",
    "    add_charge_current_day['earnings_from_battery'] = add_charge_current_day['battery_discharge'] * add_charge_current_day['MW']\n",
    "\n",
    "    # create final df with solar earnings and battery earnings by hour\n",
    "    current_df = current_df.merge(add_charge_current_day[['index','battery_discharge','earnings_from_battery']], on='index', how='left')\n",
    "\n",
    "\n",
    "    #compare totals\n",
    "    with_battery = current_df['earnings_from_battery'].sum() + current_df['earnings_per_hour_solar'].sum()\n",
    "    without_battery = current_df['earnings_per_hour'].sum()\n",
    "\n",
    "    #\n",
    "    with_battery_total.append(with_battery)\n",
    "    without_battery_total.append(without_battery)\n",
    "    difference_battery.append(with_battery - without_battery)\n",
    "    all_dfs.append(current_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns=['generation','battery discharge', 'generation og', 'batt and generation diff'], index=np.arange(len(all_dfs)))\n",
    "\n",
    "for i in np.arange(0, len(all_dfs), 1):\n",
    "    df1 = all_dfs[i]\n",
    "    df2 = daily_energy_dfs[f'df{i}']\n",
    "\n",
    "    df_test['generation'][i] = df1['Generation (MW)'].sum()\n",
    "    df_test['battery discharge'][i] = df1['battery_discharge'].sum()\n",
    "    df_test['generation og'][i] = df2['Generation (MW)'].sum()\n",
    "    df_test['batt and generation diff'][i] = (df1['Generation (MW)'].sum() + df1['battery_discharge'].sum()) - df2['Generation (MW)'].sum()\n",
    "\n",
    "# print(df['Generation (MW)'].sum())\n",
    "# print(df['battery_discharge'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate key parameters to used for LCOE formula\n",
    "\n",
    "Calculated paramaters are:\n",
    "-Annual energy (year 1) = total_annual_generation\n",
    "-DC capacity factor (year 1) = dc_capacity_factor\n",
    "-CRF\n",
    "-Operating Hours in Year (calculated by shaped of post-merge generation and price dataframes)\n",
    "\n",
    "User supplied parameters (through form) are:\n",
    "-Plant capacity\n",
    "-Plant lifetime\n",
    "-Real discount rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_operating_hours = 8760 - number_of_dropped_rows\n",
    "\n",
    "# subset columns to improve readability\n",
    "lmp_generation_combined = lmp_generation_combined[['index', 'Generation (MW)', 'NODE', 'MW']]\n",
    "\n",
    "# multiply generation per hour ['Generation (MW)'] by price per hour [MW] and put result in new column ['earnings_per_hour']\n",
    "lmp_generation_combined['earnings_per_hour'] = lmp_generation_combined['Generation (MW)'] * lmp_generation_combined['MW']\n",
    "\n",
    "# find sum of hourly generation and hourly earnings to find average earning per hour\n",
    "total_annual_generation = lmp_generation_combined['Generation (MW)'].sum()\n",
    "total_annual_earnings = lmp_generation_combined['earnings_per_hour'].sum()\n",
    "\n",
    "# divide total annual earnings by total annual generation to find average earning per hour\n",
    "average_earnings_per_hour = total_annual_earnings/total_annual_generation\n",
    "\n",
    "#calculate capacity factor using equation (total actual generation by solar plant over course of year) / (installed_capacity * (number of hours in a year)) \n",
    "# note: number of hours in a year is reduced due to slight mismatch in power generation and the lmp hourly price dataset. when joining these two datasets, several hours of the year are dropped.\n",
    "dc_capacity_factor = total_annual_generation / (user_inputs['installed_capacity'] * (8760 - number_of_dropped_rows))\n",
    "\n",
    "# crf factor used to discount project cashflows over lifetime\n",
    "crf = (user_inputs['real_discount_rate'] * (1 + user_inputs['real_discount_rate']) ** user_inputs['project_lifetime']) / ((1 + user_inputs['real_discount_rate']) ** user_inputs['project_lifetime'] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcoe = (((user_inputs['capital_cost_per_mwh']*(1-user_inputs['tax_credit'])) * user_inputs['installed_capacity'] * crf) + (user_inputs['fixed_per_mwh'] * user_inputs['installed_capacity'])) / (user_inputs['installed_capacity'] * dc_capacity_factor * annual_operating_hours)\n",
    "\n",
    "net_average_hourly_earnings = average_earnings_per_hour - lcoe\n",
    "\n",
    "print(net_average_hourly_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Build dataframe to calculate lifetime project value and graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifetime_value_df = pd.DataFrame()\n",
    "\n",
    "selected_node = lmp_only['NODE'].iat[0]\n",
    "\n",
    "lifetime_value_df['Year'] = np.arange(start= int(year), stop = int(year) + user_inputs['project_lifetime'], step= 1)\n",
    "lifetime_value_df['Years from Start'] = np.arange(start= 0, stop = user_inputs['project_lifetime'], step= 1)\n",
    "lifetime_value_df['LCOE ($/MWh)'] = round(lcoe, 2)\n",
    "lifetime_value_df[f'Income from nearest node {selected_node} ($/MWh)'] = average_earnings_per_hour\n",
    "lifetime_value_df['Inflation Adjusted Subsidy ($/MWh)'] = (user_inputs['subsidy']/((1+user_inputs['real_discount_rate'])**lifetime_value_df['Years from Start']))\n",
    "lifetime_value_df['Subsidized Income ($/MWh)'] = round(lifetime_value_df[f'Income from nearest node {selected_node} ($/MWh)'] + lifetime_value_df['Inflation Adjusted Subsidy ($/MWh)'], 2)\n",
    "lifetime_value_df['NPV Annual Income ($/Year)'] = round(((lifetime_value_df['Subsidized Income ($/MWh)'] - lifetime_value_df['LCOE ($/MWh)'])* total_annual_generation)/((1+user_inputs['real_discount_rate'])**lifetime_value_df['Years from Start']), 2)\n",
    "\n",
    "project_lifetime_value = lifetime_value_df['NPV Annual Income ($/Year)'].sum()\n",
    "\n",
    "lifetime_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Build plot of project value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "#Create graph object Figure object with data\n",
    "fig = go.Figure(data = go.Bar(x = lifetime_value_df.index, y = lifetime_value_df['NPV Annual Income ($/Year)'], marker_color='#0d6efd'))\n",
    "\n",
    "#Update layout for graph object Figure\n",
    "fig.update_layout(barmode='stack', \n",
    "                  title_text = f\"NPV Annual Income ($/Year) At Lat: {user_inputs['project_latitude']}, Lon: {user_inputs['project_longitude']}\",\n",
    "                  xaxis_title = '($/Year)',\n",
    "                  yaxis_title = 'Year',\n",
    "                  yaxis_tickprefix = '$', \n",
    "                  yaxis_tickformat = ',')\n",
    "\n",
    "fig\n",
    "\n",
    "#plotly_plot_obj = plot({'data': fig}, output_type='div')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Build interactive plot\n",
    "\n",
    "Follow this tutorial to build on previous plot and make it interactive so user can select multiple options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('energy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5532eeee86c21a3e70896f5ebe0eece70097522bb909e71ae2ecc41205f7c868"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
