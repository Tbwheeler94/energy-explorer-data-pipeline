{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **energyexplorer.io: data pipeline overview**\n",
    "\n",
    "#### **Directions for navigating notebook**\n",
    "\n",
    "Read section purpose and directions (if applicable) prior to running next code chunk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 1. Get API Key from the National Renewable Energy Lab's (NREL) National Solar Radiation Database (NSRDB)**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "This notebook remotely accesses solar radiation datasets using NSRDB's API. These datasets are used to calculate the annual solar radiation potential at a user defined latitude and longitude. \n",
    "\n",
    "To recieve data from the NSRDB's API, an API Key must be passed along with your request for data.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "1: Follow this [link](https://developer.nrel.gov/signup/) to sign up for an API Key (note: data hosting and access is a free service provide by NREL, no finanical information is required to get your key.) \\\n",
    "2: When you have acquired your API Key replace text: \"ENTER YOUR NSRDB API KEY HERE\" with the API Key. Keep the quotes surrounding your API Key. \\\n",
    "3: Run code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# API Key to access National Solar Radiation Database (NSRDB) #\n",
    "###############################################################\n",
    "\n",
    "class creds:\n",
    "    api_key = \"ENTER YOUR NSRDB API KEY HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 2. Import packages**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "In this section, you will import packages used by the data pipeline to import data and conduct analysis. This interactive jupyter notebook is being hosted by a [JupyterLite](https://jupyterlite.readthedocs.io/en/latest/) server, a separate server from energyexplorer.io.\n",
    "\n",
    "Because of this, we will need to install some packages that do not come natively with JupyterLite's kernel [Pyodide](https://pyodide.org/en/stable/). For a full list of packages included with Pyodide, [click here](https://github.com/jupyterlite/jupyterlite/tree/main/packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./packages/NREL_PySAM-4.0.0-cp310-cp310-macosx_10_15_x86_64.whl\n",
      "Requirement already satisfied: requests in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from NREL-PySAM==4.0.0) (2.28.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from NREL-PySAM==4.0.0) (0.21.0)\n",
      "Requirement already satisfied: pandas in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from NREL-PySAM==4.0.0) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from pandas->NREL-PySAM==4.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from pandas->NREL-PySAM==4.0.0) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from pandas->NREL-PySAM==4.0.0) (1.23.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests->NREL-PySAM==4.0.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests->NREL-PySAM==4.0.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests->NREL-PySAM==4.0.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests->NREL-PySAM==4.0.0) (1.26.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->NREL-PySAM==4.0.0) (1.16.0)\n",
      "NREL-PySAM is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pycaiso in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (0.2.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Tbwheeler94_1/opt/anaconda3/envs/energy/lib/python3.10/site-packages (from requests) (1.26.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "# Pyodide non-included packages local install #######################################\n",
    "#####################################################################################\n",
    "\n",
    "%pip install packages/NREL_PySAM-4.0.0-cp310-cp310-macosx_10_15_x86_64.whl\n",
    "\n",
    "#####################################################################################\n",
    "# Pyodide non-included packages written in pure python install ######################\n",
    "#####################################################################################\n",
    "\n",
    "%pip install pycaiso\n",
    "%pip install requests\n",
    "\n",
    "########################################\n",
    "# Pyodide non-included packages import #\n",
    "########################################\n",
    "\n",
    "# Import PySAM. This package provides python functions used to convert raw solar radiation values into energy generation based on the engineering parameters provided by the user\n",
    "# Learn more about PySAM here: https://pypi.org/project/NREL-PySAM/\n",
    "\n",
    "# Use site.addsitedir() to set the path to the SAM SDK API. Set path to the python directory.\n",
    "import site\n",
    "site.addsitedir('/Applications/sam-sdk-2015-6-30-r3/languages/python/')\n",
    "import PySAM.PySSC as pssc\n",
    "\n",
    "# Import pycasio. This package provides functions used to remotely access the California Independent System Operator's (CAISO) historical wholesale market price data.\n",
    "# CAISO oversees the operation of California's bulk electric power system, transmission lines, and electricity market generated and transmitted by its member utilities.\n",
    "# Learn more about CAISO here: https://www.caiso.com/Pages/default.aspx\n",
    "\n",
    "import requests\n",
    "from pycaiso.oasis import Node\n",
    "\n",
    "########################################\n",
    "# Pyodide included packages import #####\n",
    "########################################\n",
    "\n",
    "# General data wrangling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "# File management\n",
    "\n",
    "import sys, os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 3. Enter inputs for your proposed utility scale solar + battery plant into the dictionary object**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "In this section we define the parameters of our solar + battery plant. These parameters will be used throughout the data pipeline for energy and economic calculations.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Replace the default parameters with your project's proposed parameters for each ['key': value] pair (ex. 'installed_capacity': 100 -- 'installed_capacity' is the key and 100 is the value, change only the value). Replace only the value, do not alter the key. You may keep as many or all of the parameters as defaults. All parameters must be filled out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = {\n",
    "    \n",
    "    ####################################################\n",
    "    # These parameters will be passed to the NSRDB API #\n",
    "    ####################################################\n",
    "\n",
    "    # unit: degrees | dtype: float | latitude of plant\n",
    "    'project_latitude': 35.21803686349634,\n",
    "\n",
    "    # unit: degrees | dtype: float | longitude of plant\n",
    "    'project_longitude': -116.94075390362501, \n",
    "\n",
    "    # unit: years | dtype: int | lifetime of project\n",
    "    'project_lifetime': 25, \n",
    "\n",
    "    # unit: MW | dtype: int | installed capacity of solar array\n",
    "    'installed_capacity': 100,\n",
    "\n",
    "    ########################################################################################\n",
    "    # These parameters will be passed to pySAM to convert NSRDB data into solar generation #\n",
    "    ########################################################################################\n",
    "\n",
    "    # unit: none | dtype: float | ratio of installed DC capacity to the inverter's AC power rating - value should ideally be greater than 1 --> learn more here: https://tinyurl.com/49ufff42\n",
    "    'dc_ac_ratio': 1.1,\n",
    "\n",
    "    # unit: degrees | dtype: int | angle of solar array tilt relative to ground -- should be between 0 and 90 --> learn more here: https://tinyurl.com/y9v5nn3s\n",
    "    'tilt': 25,\n",
    "\n",
    "    # unit: degrees (assume north is 0 degrees) | dtype: int | angle of solar array, default value assumes due south facing\n",
    "    'azimuth': 180,\n",
    "\n",
    "    # unit: percent | dtype: int | efficiency of inverter (this is a measure of how much dc power will be converted to ac power)\n",
    "    'inv_eff': 96,\n",
    "\n",
    "    # unit: percent | dtype: float | percent of system losses\n",
    "    'losses': 14.0757,\n",
    "\n",
    "    # unit: none | dtype: int (0-4) | select solar array type (0=Fixed, 1=Fixed Roof, 2=1 Axis Tracker, 3=Backtracted, 4=2 Axis Tracker)\n",
    "    'array_type': 0,\n",
    "\n",
    "    # unit: none | dtype: float | ratio of photovoltaic area to total ground area (used to calculate total land area of plant, which is not used by energyexplorer.io) --> learn more here: https://tinyurl.com/muuwvhd2\n",
    "    'gcr': 0.4,\n",
    "\n",
    "    # unit: none | dtype: float | constant loss adjustment\n",
    "    'adjust:constant': 0,\n",
    "\n",
    "    #########################################################\n",
    "    # These parameters will be passed to the battery script #\n",
    "    #########################################################\n",
    "\n",
    "    # unit: MWh | dtype: int | total energy capacity of on-site battery\n",
    "    'battery_capacity': 400,\n",
    "\n",
    "    # unit: MW | dtype: int | rated charge power (rate of energy transfer) of on-site battery\n",
    "    'max_charge_rate': 100,\n",
    "\n",
    "    # unit: MW | dtype: int | rated discharge power (rate of energy transfer) of on-site battery\n",
    "    'max_discharge_rate': 100,\n",
    "\n",
    "    ###################################################################\n",
    "    # These parameters will be passed for final economic calculations #\n",
    "    ###################################################################\n",
    "\n",
    "    # unit: $ | dtype: int | capital cost per MWh of solar array and battery -- default value from https://www.nrel.gov/docs/fy22osti/80694.pdf does not include battery cost - page 19\n",
    "    'capital_cost_per_mwh': 890000,\n",
    "\n",
    "    # unit: $ | dtype: int | fixed cost per MWh of solar array and battery -- default value from https://www.nrel.gov/docs/fy22osti/80694.pdf does not include battery cost - page 19\n",
    "    'fixed_per_mwh': 16060,\n",
    "\n",
    "    # unit: % | dtype: int | discount rate for solar plant\n",
    "    'real_discount_rate': 5,\n",
    "\n",
    "    # unit: % | dtype: int | tax credit on capital cost of plant, in this case we assume 30% due to the passing of the IRA in 2022\n",
    "    'tax_credit': 30,\n",
    "\n",
    "    # unit: $/MWh | dtype: int | any additional subsidy per MWh of generation\n",
    "    'subsidy': 0\n",
    "\n",
    "    ###########################################################################################\n",
    "    # Note: In this example notebook, we will assume the plant will be both solar + storage ###\n",
    "    # and is selling to the open wholesale market (meaning they will recieve only), not a ppa #\n",
    "    ###########################################################################################\n",
    "\n",
    "    #'project_type': 'solar',\n",
    "    #'contract_type': 'open_market',\n",
    "    #'ppa_price': 35,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 4.a. Enter inputs for your proposed utility scale solar + battery plant into the dictionary object**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "Prepare input parameters for NSRDB API.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Assign values to first 3 variables under **User fills out** section then run code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "################ User fills out ################################\n",
    "################################################################\n",
    "\n",
    "# Your email address you used to sign up for API Key\n",
    "your_email = 'ENTER YOUR EMAIL HERE' #example: youremail@ucsb.edu\n",
    "\n",
    "# Your full name you used to sign up for API Key, use '+' instead of spaces.\n",
    "your_name = 'ENTER YOUR NAME HERE' # example: 'Your+Name'\n",
    "\n",
    "# Choose year of data using YYYY format (must keep quotes around year)\n",
    "year = 'ENTER DATE HERE' # example: '2020'\n",
    "\n",
    "################################################################\n",
    "############### Skip the rest ##################################\n",
    "################################################################\n",
    "\n",
    "# Define the lat, long of the location and the year\n",
    "lat, lon = user_inputs['project_latitude'], user_inputs['project_longitude']\n",
    "\n",
    "# lat = input() #testing input function\n",
    "# Pull api key object from creds.py\n",
    "api = creds.api_key\n",
    "\n",
    "# Set the attributes to extract (e.g., dhi, ghi, etc.), separated by commas.\n",
    "attributes = 'ghi,dhi,dni,wind_speed,air_temperature,solar_zenith_angle'\n",
    "\n",
    "# Set leap year to true or false. True will return leap day data if present, false will not.\n",
    "leap_year = 'false'\n",
    "\n",
    "# Set time interval in minutes, i.e., '30' is half hour intervals. Valid intervals are 30 & 60.\n",
    "interval = '60'\n",
    "\n",
    "# Specify Coordinated Universal Time (UTC), 'true' will use UTC, 'false' will use the local time zone of the data.\n",
    "# NOTE: In order to use the NSRDB data in SAM, you must specify UTC as 'false'. SAM requires the data to be in the\n",
    "# local time zone.\n",
    "utc = 'false'\n",
    "\n",
    "# Your reason for using the NSRDB.\n",
    "reason_for_use = 'research'\n",
    "\n",
    "# Your affiliation\n",
    "your_affiliation = 'UCSB'\n",
    "\n",
    "# Please join our mailing list so we can keep you up-to-date on new developments.\n",
    "mailing_list = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 4.b. Pull only first 2 lines of dataset from NSRDB API and timezone and elevation as objects that will be later passed into SAM model**\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timezone and elevation objects for use in SAM model\n",
    "# Declare url string\n",
    "url = 'https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap}&interval={interval}&utc={utc}&full_name={name}&email={email}&affiliation={affiliation}&mailing_list={mailing_list}&reason={reason}&api_key={api}&attributes={attr}'.format(year=year, lat=lat, lon=lon, leap=leap_year, interval=interval, utc=utc, name=your_name, email=your_email, mailing_list=mailing_list, affiliation=your_affiliation, reason=reason_for_use, api=api, attr=attributes)\n",
    "\n",
    "# Return just the first 2 lines to get metadata:\n",
    "info = pd.read_csv(url, nrows=1)\n",
    "\n",
    "# Assign timezone and elevation objects\n",
    "timezone, elevation = info['Local Time Zone'], info['Elevation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all but first 2 lines of csv to get data:\n",
    "site_generation = pd.read_csv('https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?wkt=POINT({lon}%20{lat})&names={year}&leap_day={leap}&interval={interval}&utc={utc}&full_name={name}&email={email}&affiliation={affiliation}&mailing_list={mailing_list}&reason={reason}&api_key={api}&attributes={attr}'.format(year=year, lat=lat, lon=lon, leap=leap_year, interval=interval, utc=utc, name=your_name, email=your_email, mailing_list=mailing_list, affiliation=your_affiliation, reason=reason_for_use, api=api, attr=attributes), skiprows=2)\n",
    "\n",
    "# Set the time index in the pandas dataframe:\n",
    "site_generation = site_generation.set_index(pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "\n",
    "# take a look\n",
    "site_generation.head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 5. Pass NSRDB dataset to SAM and calculate hourly energy generation at plant location**\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk and view total energy generation for year, capacity factor, and hourly generation in Generation (MW) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = pssc.PySSC()\n",
    "\n",
    "# Resource inputs for SAM model:\n",
    "# Must be byte strings\n",
    "wfd = ssc.data_create()\n",
    "ssc.data_set_number(wfd, b'lat', user_inputs['project_latitude'])\n",
    "ssc.data_set_number(wfd, b'lon', user_inputs['project_longitude'])\n",
    "ssc.data_set_number(wfd, b'tz', timezone)\n",
    "ssc.data_set_number(wfd, b'elev', elevation)\n",
    "ssc.data_set_array(wfd, b'year', site_generation.index.year)\n",
    "ssc.data_set_array(wfd, b'month', site_generation.index.month)\n",
    "ssc.data_set_array(wfd, b'day', site_generation.index.day)\n",
    "ssc.data_set_array(wfd, b'hour', site_generation.index.hour)\n",
    "ssc.data_set_array(wfd, b'minute', site_generation.index.minute)\n",
    "ssc.data_set_array(wfd, b'dn', site_generation['DNI'])\n",
    "ssc.data_set_array(wfd, b'df', site_generation['DHI'])\n",
    "ssc.data_set_array(wfd, b'wspd', site_generation['Wind Speed'])\n",
    "ssc.data_set_array(wfd, b'tdry', site_generation['Temperature'])\n",
    "\n",
    "# Create SAM compliant object  \n",
    "dat = ssc.data_create()\n",
    "ssc.data_set_table(dat, b'solar_resource_data', wfd)\n",
    "ssc.data_free(wfd)\n",
    "\n",
    "# Specify the system Configuration\n",
    "# Set system capacity in MW\n",
    "# system_capacity = 4\n",
    "\n",
    "ssc.data_set_number(dat, b'system_capacity', user_inputs['installed_capacity'])\n",
    "# Set DC/AC ratio (or power ratio). See https://sam.nrel.gov/sites/default/files/content/virtual_conf_july_2013/07-sam-virtual-conference-2013-woodcock.psite_generation\n",
    "ssc.data_set_number(dat, b'dc_ac_ratio', user_inputs['dc_ac_ratio'])\n",
    "# Set tilt of system in degrees\n",
    "ssc.data_set_number(dat, b'tilt', user_inputs['tilt'])\n",
    "# Set azimuth angle (in degrees) from north (0 degrees)\n",
    "ssc.data_set_number(dat, b'azimuth', user_inputs['azimuth'])\n",
    "# Set the inverter efficency\n",
    "ssc.data_set_number(dat, b'inv_eff', user_inputs['inv_eff'])\n",
    "# Set the system losses, in percent\n",
    "ssc.data_set_number(dat, b'losses', user_inputs['losses'])\n",
    "# Specify fixed tilt system (0=Fixed, 1=Fixed Roof, 2=1 Axis Tracker, 3=Backtracted, 4=2 Axis Tracker)\n",
    "ssc.data_set_number(dat, b'array_type', user_inputs['array_type'])\n",
    "# Set ground coverage ratio\n",
    "ssc.data_set_number(dat, b'gcr', user_inputs['gcr'])\n",
    "# Set constant loss adjustment\n",
    "ssc.data_set_number(dat, b'adjust:constant', user_inputs['adjust:constant'])\n",
    "\n",
    "# execute and put generation results back into dataframe\n",
    "mod = ssc.module_create(b'pvwattsv5')\n",
    "ssc.module_exec(mod, dat)\n",
    "site_generation['Generation (MW)'] = np.array(ssc.data_get_array(dat, b'gen'))\n",
    "\n",
    "# free the memory\n",
    "ssc.data_free(dat)\n",
    "ssc.module_free(mod)\n",
    "\n",
    "dc_capacity_factor = site_generation['Generation (MW)'].sum() / (525600/int(interval) * user_inputs['installed_capacity'])\n",
    "\n",
    "print(f\"Total electricity generation at plant location for 2020 is: {site_generation['Generation (MW)'].sum()} MWh\")\n",
    "print(f\"Capacity factor is round({dc_capacity_factor}, 3)\")\n",
    "site_generation.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 6. Find name of nearest node to your latitude and longitude**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "This section provides a quick way to extract the name of the nearest load node to your project's proposed latitude and longitude.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk and view name of node and its lat/lon as output. These values are used to show where the nearest node is located on energyexplorer.io's UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_locations = pd.read_csv('data/LMPLocations.csv')\n",
    "\n",
    "# find absolute value of user input lat/lon and node dataset lat/lon\n",
    "# and subtract data lat/lon from user input lat/lons to get differences from user supplied lat lons\n",
    "nodes_locations['latitude difference'] = abs(user_inputs['project_latitude']) - nodes_locations['latitude'].abs()\n",
    "nodes_locations['longitude difference'] = abs(user_inputs['project_longitude']) - nodes_locations['longitude'].abs()\n",
    "\n",
    "# add up absolute value of differences to find total difference then df by total difference to find location with the smallest total difference (the nearest node)\n",
    "nodes_locations['total difference'] = nodes_locations['latitude difference'].abs() + nodes_locations['longitude difference'].abs() \n",
    "nodes_locations = nodes_locations.sort_values(by=['total difference']).query(\"type == 'Load Node'\")\n",
    "\n",
    "#extra desired node variables\n",
    "node_request = nodes_locations['name'].iat[0]\n",
    "node_request_lat = nodes_locations['latitude'].iat[0]\n",
    "node_request_lon = nodes_locations['longitude'].iat[0]\n",
    "\n",
    "#show full dataframe\n",
    "print(f\"The nearest load node is {node_request} with a latitude of {node_request_lat} and a longitude of {node_request_lon}\")\n",
    "nodes_locations.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 7. Import historic locational marginal price data from HOLLISTR_1_N101 node for 2020**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "This section downloads a locally hosted csv with historical locational marginal price data from HOLLISTR_1_N101 node for 2020. In the future this section will dynamically importing historic locational marginal price data from the nearest node location via the CAISO OASIS API.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk and view name of node and its lat/lon as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HOLLISTR_1_N101 node for 2020 data\n",
    "lmp_only = pd.read_csv('data/LMP_Historic_Price.csv')\n",
    "\n",
    "# Prepare dataset for use\n",
    "lmp_only['INTERVALENDTIME_GMT'] = lmp_only['INTERVALENDTIME_GMT'].str.replace('T',' ')\n",
    "lmp_only['INTERVALENDTIME_GMT'] = lmp_only['INTERVALENDTIME_GMT'].str.replace('-00:00','')\n",
    "lmp_only['INTERVALENDTIME_GMT'] = pd.to_datetime(lmp_only['INTERVALENDTIME_GMT'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "lmp_only = lmp_only[['INTERVALENDTIME_GMT','OPR_HR', 'NODE', 'LMP_TYPE', 'MW']].sort_values(by='INTERVALENDTIME_GMT')\n",
    "\n",
    "# Preview of dataset\n",
    "lmp_only.head(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 8. Join site_generation (energy generation output at site) and lmp_only (historical marginal price at nearest wholesale node) on datetime**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "This section joins site_generation and lmp_only into one dataframe on their datetimes.\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk and view combined dataframe as well as how many rows were dropped due to some missing datetime values between the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join generation and lmp dataframes on datetime\n",
    "\n",
    "# drop datetime index and make into column named index\n",
    "site_generation.reset_index(inplace=True)\n",
    "\n",
    "# rename time column to be be index so join can be performed using index column\n",
    "lmp_only = lmp_only.rename(columns={'INTERVALENDTIME_GMT': 'index'})\n",
    "\n",
    "# merge lmp_only and site_generation on index\n",
    "# note: rows where date and time do not match will be dropped using inner join leading to a dataframe that is less than 8760 lines\n",
    "lmp_generation_combined = pd.merge(site_generation, lmp_only, how='inner', on='index')\n",
    "\n",
    "# print out the number of rows dropped to see how much mismatch there was between dfs\n",
    "number_of_dropped_rows = 8760 - lmp_generation_combined.shape[0]\n",
    "\n",
    "#reduce size of dataframe to key components\n",
    "lmp_generation_combined = lmp_generation_combined[['index', 'Generation (MW)', 'NODE', 'MW']]\n",
    "\n",
    "print(f'{number_of_dropped_rows} rows were droped')\n",
    "lmp_generation_combined.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 9. Run script to simulate additional earnings from storing generation and selling to grid during higher LMP hours**\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk and view additional earning contributions per year from the battery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#### Create lists to store and test dataframe outputs ####\n",
    "##########################################################\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "##########################################################\n",
    "###### Add date and hour values to columns in df #########\n",
    "##########################################################\n",
    "\n",
    "# create a new column using index column which has only the day, month, and year on each row\n",
    "lmp_generation_combined['index_day_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.date\n",
    "\n",
    "# create a new column using index column which has only the time\n",
    "lmp_generation_combined['index_hour_only'] = pd.to_datetime(lmp_generation_combined['index']).dt.hour\n",
    "\n",
    "# split main dataframe into 365 subdataframes each with the same index_day_only value\n",
    "daily_energy_dfs = {}\n",
    "for idx, v in enumerate(lmp_generation_combined['index_day_only'].unique()):\n",
    "    daily_energy_dfs[f'df{idx}'] = lmp_generation_combined.loc[lmp_generation_combined['index_day_only'] == v]\n",
    "\n",
    "# loop through the list of 365 dataframes, 1 dataframe at a time\n",
    "for day in np.arange(0, len(daily_energy_dfs), 1):\n",
    "    \n",
    "    # loop through the list of 365 dataframes, 1 dataframe at a time. assign current dataframe to current_df\n",
    "    current_df = daily_energy_dfs[f'df{day}'].loc[:]\n",
    "\n",
    "    # isolate df with only hours in the day where (1) there is no solar generation (2) the hour of the day is past 12 | and sort df with highest priced hours on top\n",
    "    top_values_current_day = current_df[current_df['Generation (MW)'] == 0].sort_values('MW', ascending = False).query(\"index_hour_only > 12\")\n",
    "\n",
    "    # Sort by lowest day ahead price on top to highest price on bottom. We'll assume historical data is exactly representative of day ahead hourly prices.\n",
    "    # Filter out non-producing hours as we assume battery system can only be filled by the solar system. \n",
    "    # These are the hours we'll want to be filling the battery.\n",
    "    bot_values_current_day = current_df[current_df['Generation (MW)'] != 0].sort_values('MW')\n",
    "\n",
    "    # Assign current battery charge to 0 at beginning of the day\n",
    "    # Assume battery is discharged down to 1 at night (cannot be 0 or battery_discharge_hour_counter will not function properly)\n",
    "    current_battery_charge = .00001\n",
    "\n",
    "    # Calculate earnings per hour if plant had no battery\n",
    "    current_df['earnings_per_hour'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Iterate through each row in bot_values_current_day dataframe\n",
    "    for hour in reversed(np.arange(0, len(bot_values_current_day), 1)):\n",
    "\n",
    "        # Check if battery is below capacity\n",
    "        # If battery is fully charged for the day, this loop will end\n",
    "        if current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "            # calculate what hour in the evening the battery will discharge\n",
    "            # for example: if the battery has been charged up to 70 MWh out of 400 MWh of capacity and the max discharge rate is 100 MW per hour then the current 70 MWh would be discharged in the first hour\n",
    "            # for example: if the battery has been charged up to 130 MWh out of 400 MWh of capacity and the max discharge rate is 100 MW per hour then the first 100 MWs would be discharged in the first hour and the remaining 30 MWs in the second\n",
    "            battery_discharge_hour_counter = int(np.ceil(current_battery_charge / user_inputs['max_discharge_rate'])) - 1\n",
    "\n",
    "            # Conditionally check if the price per MW during the hour that this generation would be discharged to the grid is higher than the price that is currently being asking for\n",
    "            if top_values_current_day['MW'].iat[battery_discharge_hour_counter] > bot_values_current_day['MW'].iat[hour]:\n",
    "\n",
    "                # If battery is below capacity, conditionally decide how much to fill the battery\n",
    "\n",
    "                # If total generation in that hour is more than max charging rate, then charge battery to max charge rate\n",
    "                if bot_values_current_day['Generation (MW)'].iat[hour] > user_inputs['max_charge_rate']:\n",
    "\n",
    "                    add_charge = user_inputs['max_charge_rate']\n",
    "\n",
    "                # Else charge the battery with that hour's solar system generation (which should be less than or equal to user_inputs['max_charge_rate'])\n",
    "                else:\n",
    "\n",
    "                    add_charge = bot_values_current_day['Generation (MW)'].iat[hour]\n",
    "\n",
    "                # Subtract the amount of charge added from the Generation for that hour\n",
    "                bot_values_current_day['Generation (MW)'].iat[hour] = bot_values_current_day['Generation (MW)'].iat[hour] - add_charge\n",
    "\n",
    "                # Update current battery charge with charge added\n",
    "                current_battery_charge = current_battery_charge + add_charge\n",
    "\n",
    "                # Check to see if battery capacity was exceeded (overflow charge) by adding new charge to current battery charge\n",
    "                if current_battery_charge > user_inputs['battery_capacity']:\n",
    "\n",
    "                    # Calculate overflow charge (the amount of excess charge 'sent' to the battery)\n",
    "                    extra_charge = current_battery_charge - user_inputs['battery_capacity']\n",
    "\n",
    "                    # Set current battery charge to battery_capacity by subtracting the extra charge from the total current_battery_charge\n",
    "                    current_battery_charge = current_battery_charge - extra_charge\n",
    "\n",
    "                    # Assign the overflow charge to be the generation sent to the grid for that hour. This will be the first hour on the bot_values_current_day dataframe that energy will be immediately sold to the grid\n",
    "                    bot_values_current_day['Generation (MW)'].iat[hour] = extra_charge\n",
    "\n",
    "        else:\n",
    "\n",
    "            break\n",
    "    \n",
    "\n",
    "    #Overwrite current_df generation values with bot_values_current_day to reflect energy sent to battery instead of grid\n",
    "    current_df = current_df.set_index('index')\n",
    "    current_df.update(bot_values_current_day.set_index('index'))\n",
    "    current_df = current_df.reset_index()\n",
    "\n",
    "    ###############################################\n",
    "    ### Calculate solar revenue for current day ###\n",
    "    ###############################################\n",
    "\n",
    "    # Calculate the earning per hour for solar only\n",
    "    current_df['earnings_per_hour_solar'] = current_df['Generation (MW)'] * current_df['MW']\n",
    "\n",
    "    # Assign total revenue for that day from solar as an object\n",
    "    #solar_revenue_sum = bot_values_current_day['earnings_per_hour_solar'].sum()\n",
    "\n",
    "    #################################################\n",
    "    ### Calculate battery revenue for current day ###\n",
    "    #################################################\n",
    "\n",
    "    #update battery discharge counter again to account for last charge added to battery\n",
    "    battery_discharge_hour_counter = int(np.ceil(current_battery_charge / user_inputs['max_discharge_rate']))\n",
    "\n",
    "    add_charge_current_day = current_df[current_df['Generation (MW)'] == 0].sort_values('MW', ascending=False).query(\"index_hour_only > 12\").nlargest(n= battery_discharge_hour_counter, columns = 'MW')\n",
    "    \n",
    "    if current_battery_charge > user_inputs['max_discharge_rate'] and current_battery_charge < user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "        add_charge_current_day['battery_discharge'].iat[-1] = current_battery_charge % user_inputs['max_discharge_rate']\n",
    "\n",
    "    elif current_battery_charge == user_inputs['battery_capacity']:\n",
    "\n",
    "        add_charge_current_day['battery_discharge'] = user_inputs['max_discharge_rate']\n",
    "\n",
    "    else:\n",
    "        \n",
    "        add_charge_current_day['battery_discharge'] = current_battery_charge\n",
    "    \n",
    "    add_charge_current_day['earnings_from_battery'] = add_charge_current_day['battery_discharge'] * add_charge_current_day['MW']\n",
    "\n",
    "    # create final df with solar earnings and battery earnings by hour\n",
    "    current_df = current_df.merge(add_charge_current_day[['index','battery_discharge','earnings_from_battery']], on='index', how='left')\n",
    "    \n",
    "    all_dfs.append(current_df)\n",
    "\n",
    "generation_with_battery = pd.concat(all_dfs).fillna(0)\n",
    "\n",
    "generation_with_battery['earnings_from_battery_and_solar'] = generation_with_battery['earnings_per_hour_solar'] + generation_with_battery['earnings_from_battery']\n",
    "\n",
    "additional_earnings_from_battery = round(generation_with_battery['earnings_from_battery_and_solar'].sum() - generation_with_battery['earnings_per_hour'].sum(), 2)\n",
    "\n",
    "print(f\"By adding a battery the plant earns an additional ${additional_earnings_from_battery} per year\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 10. Calculate remaining parameters for LCOE and calculate LCOE**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "In this section we calculate the following parameters used in the LCOE formula:\n",
    "\n",
    "Calculated paramaters are:\n",
    "- Annual operating hours (calculated by shaped of post-merge generation and price dataframes) = annual_operating_hours\n",
    "- CRF = crf \n",
    "\n",
    "The calculated parameters will be needed in addtion to the following previously user supplied parameters in Section 3:\n",
    "- Plant capacity\n",
    "- Plant lifetime\n",
    "- Real discount rate\n",
    "- Tax credit\n",
    "\n",
    "And the following previously calculated parameters:\n",
    "- DC capacity factor (year 1) = dc_capacity_factor\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk to calculate parameters and see LCOE output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of annual operating hours\n",
    "annual_operating_hours = 8760 - number_of_dropped_rows\n",
    "\n",
    "# crf factor used to discount project cashflows over lifetime\n",
    "crf = (user_inputs['real_discount_rate']/100 * (1 + user_inputs['real_discount_rate']/100) ** user_inputs['project_lifetime']) / ((1 + user_inputs['real_discount_rate']/100) ** user_inputs['project_lifetime'] - 1)\n",
    "\n",
    "# calculate lcoe\n",
    "lcoe = round((((user_inputs['capital_cost_per_mwh']*(1-user_inputs['tax_credit']/100)) * user_inputs['installed_capacity'] * crf) + (user_inputs['fixed_per_mwh'] * user_inputs['installed_capacity'])) / (user_inputs['installed_capacity'] * dc_capacity_factor * annual_operating_hours),2)\n",
    "\n",
    "print(f\"Levelized cost of energy is ${lcoe}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 11. Calculate average earnings in dollars per MWh and net average earnings in dollars per MWh after subtracting LCOE**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "In this section we calculate total annual generation (which accounts for the reduction in the size of the dataframe after the merge) and total annual earnings a parameters to calculate average earning per MWh\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply generation per hour ['Generation (MW)'] by price per hour [MW] and put result in new column ['earnings_per_hour']\n",
    "lmp_generation_combined['earnings_per_hour'] = lmp_generation_combined['Generation (MW)'] * lmp_generation_combined['MW']\n",
    "\n",
    "# find sum of hourly generation and hourly earnings to find average earning per hour\n",
    "total_annual_generation = lmp_generation_combined['Generation (MW)'].sum()\n",
    "total_annual_earnings = lmp_generation_combined['earnings_per_hour'].sum()\n",
    "\n",
    "# divide total annual earnings by total annual generation to find average earning per hour\n",
    "average_earnings_per_mwh = total_annual_earnings/total_annual_generation\n",
    "\n",
    "net_average_earnings_per_mwh = round(average_earnings_per_mwh - lcoe, 3)\n",
    "\n",
    "print(f\"Average net earnings is ${net_average_earnings_per_mwh} per MWh\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Section 12. Calculate lifetime value of solar + battery plant**\n",
    "\n",
    "#### **Directions**\n",
    "\n",
    "Run code chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifetime_value_df = pd.DataFrame()\n",
    "\n",
    "selected_node = lmp_only['NODE'].iat[0]\n",
    "\n",
    "lifetime_value_df['Year'] = np.arange(start= int(year), stop = int(year) + user_inputs['project_lifetime'], step= 1)\n",
    "lifetime_value_df['Years from Start'] = np.arange(start= 0, stop = user_inputs['project_lifetime'], step= 1)\n",
    "lifetime_value_df['LCOE ($/MWh)'] = round(lcoe, 2)\n",
    "lifetime_value_df[f'Income from nearest node {selected_node} ($/MWh)'] = average_earnings_per_mwh\n",
    "lifetime_value_df['Inflation Adjusted Subsidy ($/MWh)'] = (user_inputs['subsidy']/((1+(user_inputs['real_discount_rate']/100))**lifetime_value_df['Years from Start']))\n",
    "lifetime_value_df['Subsidized Income ($/MWh)'] = round(lifetime_value_df[f'Income from nearest node {selected_node} ($/MWh)'] + lifetime_value_df['Inflation Adjusted Subsidy ($/MWh)'], 2)\n",
    "lifetime_value_df['NPV Annual Income ($/Year)'] = round(((lifetime_value_df['Subsidized Income ($/MWh)'] - lifetime_value_df['LCOE ($/MWh)'])* total_annual_generation)/((1+(user_inputs['real_discount_rate']/100))**lifetime_value_df['Years from Start']), 2)\n",
    "\n",
    "project_lifetime_value = round(lifetime_value_df['NPV Annual Income ($/Year)'].sum(), 3)\n",
    "\n",
    "print(f\"Lifetime value of project is ${project_lifetime_value}\")\n",
    "lifetime_value_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Build plot of NPV of cashflow streams from plant through time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "#Create graph object Figure object with data\n",
    "fig = go.Figure(data = go.Bar(x = lifetime_value_df.index, y = lifetime_value_df['NPV Annual Income ($/Year)'], marker_color='#0d6efd'))\n",
    "\n",
    "#Update layout for graph object Figure\n",
    "fig.update_layout(barmode='stack', \n",
    "                  title_text = f\"NPV Annual Income ($/Year) At Lat: {user_inputs['project_latitude']}, Lon: {user_inputs['project_longitude']}\",\n",
    "                  xaxis_title = '($/Year)',\n",
    "                  yaxis_title = 'Year',\n",
    "                  yaxis_tickprefix = '$', \n",
    "                  yaxis_tickformat = ',')\n",
    "\n",
    "fig\n",
    "\n",
    "#plotly_plot_obj = plot({'data': fig}, output_type='div')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5181aa0f3b9f412fbf10d6412c76aa827a0c11ab84c80162367ae08ef653f3ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
